{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ia369y-test-note-p3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/edgarbanhesse/ia369y-affective-computing/blob/master/ia369y_test_note_p3.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "_qQv_Tjki_wx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "62d6051e-9945-4b95-ff77-70dc011e4f82"
      },
      "cell_type": "code",
      "source": [
        "# https://pythonspot.com/python-sentiment-analysis\n",
        "# Exemplo de uso do classificados NaiveBayes\n",
        "\n",
        "import nltk.classify.util\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.corpus import names\n",
        " \n",
        "def word_feats(words):\n",
        "    return dict([(word, True) for word in words])\n",
        " \n",
        "positive_vocab = [ 'awesome', 'outstanding', 'fantastic', 'terrific', 'good', 'nice', 'great', ':)' ]\n",
        "negative_vocab = [ 'bad', 'terrible','useless', 'hate', ':(' ]\n",
        "neutral_vocab = [ 'movie','the','sound','was','is','actors','did','know','words','not' ]\n",
        " \n",
        "positive_features = [(word_feats(pos), 'pos') for pos in positive_vocab]\n",
        "negative_features = [(word_feats(neg), 'neg') for neg in negative_vocab]\n",
        "neutral_features = [(word_feats(neu), 'neu') for neu in neutral_vocab]\n",
        " \n",
        "train_set = negative_features + positive_features + neutral_features\n",
        " \n",
        "classifier = NaiveBayesClassifier.train(train_set) \n",
        " \n",
        "# Predict\n",
        "neg = 0\n",
        "pos = 0\n",
        "sentence = \"Awesome movie, I liked it\"\n",
        "sentence = sentence.lower()\n",
        "words = sentence.split(' ')\n",
        "for word in words:\n",
        "    classResult = classifier.classify( word_feats(word))\n",
        "    if classResult == 'neg':\n",
        "        neg = neg + 1\n",
        "    if classResult == 'pos':\n",
        "        pos = pos + 1\n",
        "\n",
        "# print(positive_vocab)\n",
        "# print(positive_features)\n",
        "# print(train_set)\n",
        "\n",
        "print('Positive: ' + str(float(pos)/len(words)))\n",
        "print('Negative: ' + str(float(neg)/len(words)))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive: 0.6\n",
            "Negative: 0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X6OFZoHmcXhN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "289d5af3-80f5-49e8-be6a-4a49a92ac530"
      },
      "cell_type": "code",
      "source": [
        "# Fonte: https://medium.freecodecamp.org/how-to-process-textual-data-using-tf-idf-in-python-cd2bbc0a94a3\n",
        "# Teste de cálculo do tf\n",
        "def computeTF(wordDict, bow):\n",
        "    tfDict = {}\n",
        "    bowCount = len(bow)\n",
        "    for word, count in wordDict.items():\n",
        "        tfDict[word] = count/float(bowCount)\n",
        "    return tfDict\n",
        "\n",
        "S1 = \"The car is driven on the road\"\n",
        "S2 = \"The truck is driven on the highway\"\n",
        "\n",
        "bow1 = S1.split(\" \")\n",
        "bow2 = S2.split(\" \")\n",
        "\n",
        "wordSet = set(bow1).union(set(bow2))\n",
        "\n",
        "wordDict1 = dict.fromkeys(wordSet, 0) \n",
        "wordDict2 = dict.fromkeys(wordSet, 0) \n",
        "\n",
        "for word in bow1:\n",
        "    wordDict1[word]+=1\n",
        "    \n",
        "for word in bow2:\n",
        "    wordDict2[word]+=1\n",
        "    \n",
        "import pandas as pd\n",
        "pd.DataFrame([wordDict1, wordDict2])\n",
        "\n",
        "tfBow1 = computeTF(wordDict1, bow1)\n",
        "tfBow2 = computeTF(wordDict2, bow2)\n",
        "\n",
        "tfBow1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'The': 0.14285714285714285,\n",
              " 'car': 0.14285714285714285,\n",
              " 'driven': 0.14285714285714285,\n",
              " 'highway': 0.0,\n",
              " 'is': 0.14285714285714285,\n",
              " 'on': 0.14285714285714285,\n",
              " 'road': 0.14285714285714285,\n",
              " 'the': 0.14285714285714285,\n",
              " 'truck': 0.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "-FGg_4X8PaiG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "8bb0fde5-7d93-48be-c04c-61a958150368"
      },
      "cell_type": "code",
      "source": [
        "tfBow2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'The': 0.14285714285714285,\n",
              " 'car': 0.0,\n",
              " 'driven': 0.14285714285714285,\n",
              " 'highway': 0.14285714285714285,\n",
              " 'is': 0.14285714285714285,\n",
              " 'on': 0.14285714285714285,\n",
              " 'road': 0.0,\n",
              " 'the': 0.14285714285714285,\n",
              " 'truck': 0.14285714285714285}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "luYKkrlBtv5e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "ca025109-20bb-4275-a2ac-0a0c9f3d50dd"
      },
      "cell_type": "code",
      "source": [
        "# Teste de cálculo do idf\n",
        "def computeIDF(docList):\n",
        "    import math\n",
        "    idfDict = {}\n",
        "    N = len(docList)\n",
        "    \n",
        "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
        "    for doc in docList:\n",
        "        for word, val in doc.items():\n",
        "            if val > 0:\n",
        "                idfDict[word] += 1\n",
        "    \n",
        "    for word, val in idfDict.items():\n",
        "        idfDict[word] = math.log10(N / float(val))\n",
        "        \n",
        "    return idfDict\n",
        "  \n",
        "idfs = computeIDF([wordDict1, wordDict2])\n",
        "idfs"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'The': 0.0,\n",
              " 'car': 0.3010299956639812,\n",
              " 'driven': 0.0,\n",
              " 'highway': 0.3010299956639812,\n",
              " 'is': 0.0,\n",
              " 'on': 0.0,\n",
              " 'road': 0.3010299956639812,\n",
              " 'the': 0.0,\n",
              " 'truck': 0.3010299956639812}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "Sd6Ho4ISvq-t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "6359aa23-d3a7-471a-9c13-a51078a79241"
      },
      "cell_type": "code",
      "source": [
        "# Teste de cálculo do tfidf\n",
        "def computeTFIDF(tfBow, idfs):\n",
        "    tfidf = {}\n",
        "    for word, val in tfBow.items():\n",
        "        tfidf[word] = val*idfs[word]\n",
        "    return tfidf\n",
        "  \n",
        "tfidfBow1 = computeTFIDF(tfBow1, idfs)\n",
        "tfidfBow2 = computeTFIDF(tfBow2, idfs)\n",
        "\n",
        "import pandas as pd\n",
        "pd.DataFrame([tfidfBow1, tfidfBow2])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>The</th>\n",
              "      <th>car</th>\n",
              "      <th>driven</th>\n",
              "      <th>highway</th>\n",
              "      <th>is</th>\n",
              "      <th>on</th>\n",
              "      <th>road</th>\n",
              "      <th>the</th>\n",
              "      <th>truck</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043004</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043004</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043004</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043004</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   The       car  driven   highway   is   on      road  the     truck\n",
              "0  0.0  0.043004     0.0  0.000000  0.0  0.0  0.043004  0.0  0.000000\n",
              "1  0.0  0.000000     0.0  0.043004  0.0  0.0  0.000000  0.0  0.043004"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "QL3IIGs916wG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "ce1fc6b8-5629-464f-ed63-58c335c0348c"
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
        "\n",
        "# Classe do T2\n",
        "class TfidfImpl:\n",
        "\n",
        "    def __init__(self, stopwords=None):\n",
        "        self.stopwords = stopwords\n",
        "    \n",
        "    def clean_phrase(self, phrase):\n",
        "        phrase = phrase.lower()\n",
        "        # Remove pontuação\n",
        "        phrase = re.sub(r'[\\\"\\'!@#$%&*\\(\\)-_=+{}\\[\\]:;>.<,|\\\\`´]', '', phrase)\n",
        "        if self.stopwords == 'english':\n",
        "            # Remover stopwords em inglês e Lematização das palavras\n",
        "            wordnet_lemmatizer = WordNetLemmatizer()\n",
        "            # stwords = set(stopwords.words('english'))\n",
        "            stwords = set(ENGLISH_STOP_WORDS)\n",
        "            phrase = ' '.join([wordnet_lemmatizer.lemmatize(word) for word in phrase.split() if word not in stwords and len(word) > 2])\n",
        "        # Remove espaços em branco extras\n",
        "        phrase = re.sub(r'\\s{1,}', ' ', phrase)\n",
        "        return phrase\n",
        "\n",
        "\n",
        "    def tokenize(self, phrase):\n",
        "        # Limpar e retorna trigramas da frase\n",
        "        return self.clean_phrase(phrase).split()\n",
        "    \n",
        "    def bag_of_words(self, phrases):\n",
        "        bow = []\n",
        "        for phrase in phrases:\n",
        "            bow += phrase\n",
        "        return sorted(set(bow))\n",
        "\n",
        "\n",
        "    def compute_tf(self, words):\n",
        "        tf = {}\n",
        "        lbow = len(words)\n",
        "        for word in words:\n",
        "            tf[word] = tf.get(word, 0) + 1\n",
        "        for word, count in tf.items():\n",
        "            tf[word] = count / lbow\n",
        "        return tf\n",
        "\n",
        "\n",
        "    def compute_idf(self, phrases, N, bow):\n",
        "        idfs = {}\n",
        "        for df in bow:\n",
        "            idfs[df] = idfs.get(df, 0)\n",
        "            for words in phrases:\n",
        "                if df in words:\n",
        "                    idfs[df] = idfs.get(df, 0) + 1\n",
        "        for df in idfs.keys():\n",
        "            idfs[df] = np.log10(N / idfs[df])\n",
        "        return idfs\n",
        "\n",
        "\n",
        "    def compute(self, phrases):\n",
        "        # Checagem... e conversão\n",
        "        assert len(phrases) > 0\n",
        "        if type(phrases[0]) is str:\n",
        "            phrases = [self.tokenize(phrase) for phrase in phrases]\n",
        "        \n",
        "        tf_idf = {}\n",
        "        N = len(phrases)\n",
        "        bow = self.bag_of_words(phrases)\n",
        "        idf = self.compute_idf(phrases, N, bow)\n",
        "        for words in phrases:\n",
        "            tf = self.compute_tf(words)\n",
        "            for word, val in tf.items():\n",
        "                tf_idf[word] = val * idf[word]\n",
        "        return tf_idf\n",
        "\n",
        "# Teste tfidf\n",
        "\n",
        "my_phrases = ['The car is driven on the road', 'The truck is driven on the highway']\n",
        "\n",
        "print('Teste da nossa implementação:')\n",
        "tfidf = TfidfImpl()\n",
        "tfidf = tfidf.compute(my_phrases)\n",
        "tfidf"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Teste da nossa implementação:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'car': 0.043004285094854454,\n",
              " 'driven': 0.0,\n",
              " 'highway': 0.043004285094854454,\n",
              " 'is': 0.0,\n",
              " 'on': 0.0,\n",
              " 'road': 0.043004285094854454,\n",
              " 'the': 0.0,\n",
              " 'truck': 0.043004285094854454}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "ZlDm0oCRKaJF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "159898b0-2867-452c-b2a5-196a9294e7bd"
      },
      "cell_type": "code",
      "source": [
        "# Teste tfidf sklearn\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.preprocessing import normalize\n",
        "import pandas as pd\n",
        "\n",
        "# corpus = {1: \"The game of life is a game of everlasting learning\", 2: \"The unexamined life is not worth living\", 3: \"Never stop learning\"}\n",
        "corpus = {1: \"The car is driven on the road\", 2: \"The truck is driven on the highway\"}\n",
        "\n",
        "cvect = CountVectorizer(ngram_range=(1,1), token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
        "counts = cvect.fit_transform(corpus.values())\n",
        "normalized_counts = normalize(counts, norm='l1', axis=1)\n",
        "\n",
        "tfidf = TfidfVectorizer(ngram_range=(1,1), token_pattern='(?u)\\\\b\\\\w+\\\\b', smooth_idf=False)\n",
        "tfs = tfidf.fit_transform(corpus.values())\n",
        "new_tfs = normalized_counts.multiply(tfidf.idf_)\n",
        "\n",
        "feature_names = tfidf.get_feature_names()\n",
        "corpus_index = [n for n in corpus]\n",
        "df = pd.DataFrame(new_tfs.T.todense(), index=feature_names, columns=corpus_index)\n",
        "\n",
        "print(df.loc[['The', 'car', 'driven', 'highway', 'is', 'on', 'road', 'the', 'truck']])\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                1         2\n",
            "The           NaN       NaN\n",
            "car      0.241878  0.000000\n",
            "driven   0.142857  0.142857\n",
            "highway  0.000000  0.241878\n",
            "is       0.142857  0.142857\n",
            "on       0.142857  0.142857\n",
            "road     0.241878  0.000000\n",
            "the      0.285714  0.285714\n",
            "truck    0.000000  0.241878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: FutureWarning: \n",
            "Passing list-likes to .loc or [] with any missing label will raise\n",
            "KeyError in the future, you can use .reindex() as an alternative.\n",
            "\n",
            "See the documentation here:\n",
            "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "yxxBQ5Skf2PK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2c3baa0f-a7fb-422d-8fa2-6542577b68f4"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.random.randint(5, size=(6, 100))\n",
        "y = np.array([1, 2, 3, 4, 5, 6])\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X, y)\n",
        "\n",
        "print(clf.predict(X[2:3]))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HbxDLgeugYZe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "43a98f9b-3ec2-4b6c-963f-8b5a146647d6"
      },
      "cell_type": "code",
      "source": [
        "X = [[0], [1], [2], [3]]\n",
        "y = [0, 0, 1, 1]\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(X, y) \n",
        "\n",
        "print(neigh.predict([[1.1]]))\n",
        "\n",
        "print(neigh.predict_proba([[0.9]]))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n",
            "[[0.66666667 0.33333333]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}